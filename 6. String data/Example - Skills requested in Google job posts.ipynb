{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skills requested in Google job posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which **language, skills, and experience** should we add to our toolbox for getting a job in Google? Google publishes all of their jobs at `careers.google.com`. Niyamat Ullah scraped all of the job data from that site by capturing the source code of every job page with a tool called **Selenium**, extracting the job title, location, responsibilities, minimum and preferred qualifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `google.csv` contains data from 1,250 job positions. The variables are:\n",
    "\n",
    "* `company`: either Google or Youtube.\n",
    "\n",
    "* `title`: the title of the job.\n",
    "\n",
    "* `category`: the category of the job.\n",
    "\n",
    "* `location`: the location of the job.\n",
    "\n",
    "* `responsibilities`: the responsibilities for the job.\n",
    "\n",
    "* `minqual`: the minimum qualifications for the job.\n",
    "\n",
    "* `prefqual`: the preferred qualifications for the job.\n",
    "\n",
    "Source: Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I import the data from a remote CSV file as usual. Since the job posts do not come with an identifier, none of the columns of the source file can be used as the index. So, I don't use the argument `index_col` in this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mcanela-iese/DataScience/main/Data/google.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, I check, with the functions `info` and `head`, that the content of the file is as expected. A few missing values are detected in the last three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1250 entries, 0 to 1249\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   company           1250 non-null   object\n",
      " 1   title             1250 non-null   object\n",
      " 2   category          1250 non-null   object\n",
      " 3   location          1250 non-null   object\n",
      " 4   responsibilities  1235 non-null   object\n",
      " 5   minqual           1236 non-null   object\n",
      " 6   prefqual          1236 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 68.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>location</th>\n",
       "      <th>responsibilities</th>\n",
       "      <th>minqual</th>\n",
       "      <th>prefqual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>Google Cloud Program Manager</td>\n",
       "      <td>Program Management</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Shape, shepherd, ship, and show technical prog...</td>\n",
       "      <td>BA/BS degree or equivalent practical experienc...</td>\n",
       "      <td>Experience in the business technology market a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>Supplier Development Engineer (SDE), Cable/Con...</td>\n",
       "      <td>Manufacturing &amp; Supply Chain</td>\n",
       "      <td>Shanghai, China</td>\n",
       "      <td>Drive cross-functional activities in the suppl...</td>\n",
       "      <td>BS degree in an Engineering discipline or equi...</td>\n",
       "      <td>BSEE, BSME or BSIE degree.\\nExperience of usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>Data Analyst, Product and Tools Operations, Go...</td>\n",
       "      <td>Technical Solutions</td>\n",
       "      <td>New York, NY, United States</td>\n",
       "      <td>Collect and analyze data to draw insight and i...</td>\n",
       "      <td>Bachelor’s degree in Business, Economics, Stat...</td>\n",
       "      <td>Experience partnering or consulting cross-func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>Developer Advocate, Partner Engineering</td>\n",
       "      <td>Developer Relations</td>\n",
       "      <td>Mountain View, CA, United States</td>\n",
       "      <td>Work one-on-one with the top Android, iOS, and...</td>\n",
       "      <td>BA/BS degree in Computer Science or equivalent...</td>\n",
       "      <td>Experience as a software developer, architect,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>Program Manager, Audio Visual (AV) Deployments</td>\n",
       "      <td>Program Management</td>\n",
       "      <td>Sunnyvale, CA, United States</td>\n",
       "      <td>Plan requirements with internal customers.\\nPr...</td>\n",
       "      <td>BA/BS degree or equivalent practical experienc...</td>\n",
       "      <td>CTS Certification.\\nExperience in the construc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company                                              title  \\\n",
       "0  Google                       Google Cloud Program Manager   \n",
       "1  Google  Supplier Development Engineer (SDE), Cable/Con...   \n",
       "2  Google  Data Analyst, Product and Tools Operations, Go...   \n",
       "3  Google            Developer Advocate, Partner Engineering   \n",
       "4  Google     Program Manager, Audio Visual (AV) Deployments   \n",
       "\n",
       "                       category                          location  \\\n",
       "0            Program Management                         Singapore   \n",
       "1  Manufacturing & Supply Chain                   Shanghai, China   \n",
       "2           Technical Solutions       New York, NY, United States   \n",
       "3           Developer Relations  Mountain View, CA, United States   \n",
       "4            Program Management      Sunnyvale, CA, United States   \n",
       "\n",
       "                                    responsibilities  \\\n",
       "0  Shape, shepherd, ship, and show technical prog...   \n",
       "1  Drive cross-functional activities in the suppl...   \n",
       "2  Collect and analyze data to draw insight and i...   \n",
       "3  Work one-on-one with the top Android, iOS, and...   \n",
       "4  Plan requirements with internal customers.\\nPr...   \n",
       "\n",
       "                                             minqual  \\\n",
       "0  BA/BS degree or equivalent practical experienc...   \n",
       "1  BS degree in an Engineering discipline or equi...   \n",
       "2  Bachelor’s degree in Business, Economics, Stat...   \n",
       "3  BA/BS degree in Computer Science or equivalent...   \n",
       "4  BA/BS degree or equivalent practical experienc...   \n",
       "\n",
       "                                            prefqual  \n",
       "0  Experience in the business technology market a...  \n",
       "1  BSEE, BSME or BSIE degree.\\nExperience of usin...  \n",
       "2  Experience partnering or consulting cross-func...  \n",
       "3  Experience as a software developer, architect,...  \n",
       "4  CTS Certification.\\nExperience in the construc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated job posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of duplicated rows in this data set is obtained in the usual way. `duplicated` returns a Boolean series indicating the duplicated rows. Then, `sum` returns the number of `True` values in that mask.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no ID for the job post, we cannot decide whether the duplication is really wrong. It may be that the data collector was careless in the web scraping process, but also that Google posted repeatedly the same job offer (or whatever). For this example, I take those duplicates as errors, so I drop them. This can be done with the function `drop_duplicates`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1127 entries, 0 to 1249\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   company           1127 non-null   object\n",
      " 1   title             1127 non-null   object\n",
      " 2   category          1127 non-null   object\n",
      " 3   location          1127 non-null   object\n",
      " 4   responsibilities  1112 non-null   object\n",
      " 5   minqual           1113 non-null   object\n",
      " 6   prefqual          1113 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the company\n",
    "\n",
    "The first column has the company name. The analysis is very simple, since the company is either Google or YouTube (a few cases). The function `value_counts` does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Google     1107\n",
       "YouTube      20\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['company'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the job title\n",
    "\n",
    "The data set seems to include many different job titles. `value_counts` returns one count for each title, so the number of unique job titles can be obtained as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. `len(df['title'].unique())` would give us the same number.\n",
    "\n",
    "The top-10 titles are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Intern 2018                            33\n",
       "Field Sales Representative, Google Cloud        17\n",
       "Interaction Designer                            12\n",
       "MBA Intern, Summer 2018                         10\n",
       "User Experience Researcher                       9\n",
       "MBA Intern 2018                                  7\n",
       "BOLD Intern, Summer 2018                         7\n",
       "User Experience Design Intern, Summer 2018       7\n",
       "Partner Sales Engineer, Google Cloud             7\n",
       "User Experience Research Intern, Summer 2018     6\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interns seem to dominate the picture, but, with 794 different titles, this quick view could be misleading. So, I check other possibilities. The function `str.contains` returns a Boolean series indicating whether a given pattern is contained in every term of the series. So, we count the jobs whose title contains the word 'Intern' with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].str.contains('Intern').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me try other expressions, to compare with 'Intern':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].str.contains('Sales').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].str.contains('Cloud').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].str.contains('Google Cloud').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job categories look more promising to the analyst, since they are described in a more systematic way. There are 23 different categories here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-10 categories are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sales & Account Management      167\n",
       "Marketing & Communications      154\n",
       "Technical Solutions             101\n",
       "Finance                          86\n",
       "People Operations                85\n",
       "User Experience & Design         84\n",
       "Program Management               69\n",
       "Business Strategy                65\n",
       "Partnerships                     54\n",
       "Legal & Government Relations     45\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is typical of these data sets that the location comes as *city, state, country* for US and Canada (sometimes also for India and others), but as *city, country* for other countries. The country can be extracted by deleting every sequence of characters that ends with a comma followed by a white space. A **regular expression** for this pattern is `'.+, '`. The dot (`.`) is a **wildcard** which stands for any character, and the plus sign (`+`) is a **quantifier** which is read as *any length*.\n",
    "\n",
    "The method `str.replace` using the **empty string** as the replacement performs the deletion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = df['location'].str.replace(pat='.+, ', repl='', regex=True)\n",
    "len(country.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `regex=True` may not be needed, depending of the version of Pandas that you use., but it is better to control these details, so the code gets more robust. Again, the same job can be done with `apply` and a lambda function, or with a `for` loop (using on the function `sub`, from the package `re`). \n",
    "\n",
    "There are 49 countries, though, as you can see below, most of the job requests are for US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States     572\n",
       "Ireland            87\n",
       "United Kingdom     58\n",
       "Germany            53\n",
       "Singapore          36\n",
       "Australia          33\n",
       "China              32\n",
       "Japan              30\n",
       "Taiwan             27\n",
       "India              25\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the last three columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values in the last three columns this data set. Let us see whether the missingness occurs for the same job posts. For each column, the method `isna`creates a Boolean mask. Combining the three masks with the OR operator (`|`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>location</th>\n",
       "      <th>responsibilities</th>\n",
       "      <th>minqual</th>\n",
       "      <th>prefqual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Google</td>\n",
       "      <td>Manufacturing Test Engineer</td>\n",
       "      <td>Hardware Engineering</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Google</td>\n",
       "      <td>Software Engineer, Android Applications, Veril...</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Cambridge, MA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Google</td>\n",
       "      <td>Analog / Mixed Signal IC Design Engineer, Veri...</td>\n",
       "      <td>Hardware Engineering</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Google</td>\n",
       "      <td>Program Manager, Behavioral Health, Verily Lif...</td>\n",
       "      <td>Program Management</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Google</td>\n",
       "      <td>Software Engineer, Android Applications, Veril...</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Google</td>\n",
       "      <td>Manufacturing Engineer, Verily Life Sciences -...</td>\n",
       "      <td>Hardware Engineering</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Google</td>\n",
       "      <td>IC Test Engineer, Verily Life Sciences - South...</td>\n",
       "      <td>Hardware Engineering</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Google</td>\n",
       "      <td>Software Engineer, Verily Life Sciences - Sout...</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Google</td>\n",
       "      <td>Firmware Engineer, Verily Life Sciences - Sout...</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Google</td>\n",
       "      <td>Software Test Engineer, Mobile and Web Applica...</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Mountain View, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Google</td>\n",
       "      <td>iOS Application Developer, Project Baseline, V...</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Mountain View, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Google</td>\n",
       "      <td>Technical Solutions Consultant, Verily Life Sc...</td>\n",
       "      <td>Technical Solutions</td>\n",
       "      <td>Mountain View, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Google</td>\n",
       "      <td>Technical Program Manager, Test Engineering, V...</td>\n",
       "      <td>Program Management</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Google</td>\n",
       "      <td>Software Test Engineer, Devices, Verily Life S...</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>South San Francisco, CA, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Google</td>\n",
       "      <td>Strategic Partner Development Manager, Retail ...</td>\n",
       "      <td>Partnerships</td>\n",
       "      <td>München, Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA/BS degree or equivalent practical experienc...</td>\n",
       "      <td>Relevant experience in sales management, busin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    company                                              title  \\\n",
       "15   Google                        Manufacturing Test Engineer   \n",
       "72   Google  Software Engineer, Android Applications, Veril...   \n",
       "91   Google  Analog / Mixed Signal IC Design Engineer, Veri...   \n",
       "97   Google  Program Manager, Behavioral Health, Verily Lif...   \n",
       "98   Google  Software Engineer, Android Applications, Veril...   \n",
       "123  Google  Manufacturing Engineer, Verily Life Sciences -...   \n",
       "150  Google  IC Test Engineer, Verily Life Sciences - South...   \n",
       "160  Google  Software Engineer, Verily Life Sciences - Sout...   \n",
       "202  Google  Firmware Engineer, Verily Life Sciences - Sout...   \n",
       "206  Google  Software Test Engineer, Mobile and Web Applica...   \n",
       "210  Google  iOS Application Developer, Project Baseline, V...   \n",
       "230  Google  Technical Solutions Consultant, Verily Life Sc...   \n",
       "241  Google  Technical Program Manager, Test Engineering, V...   \n",
       "286  Google  Software Test Engineer, Devices, Verily Life S...   \n",
       "307  Google  Strategic Partner Development Manager, Retail ...   \n",
       "\n",
       "                 category                                location  \\\n",
       "15   Hardware Engineering  South San Francisco, CA, United States   \n",
       "72   Software Engineering            Cambridge, MA, United States   \n",
       "91   Hardware Engineering  South San Francisco, CA, United States   \n",
       "97     Program Management  South San Francisco, CA, United States   \n",
       "98   Software Engineering  South San Francisco, CA, United States   \n",
       "123  Hardware Engineering  South San Francisco, CA, United States   \n",
       "150  Hardware Engineering  South San Francisco, CA, United States   \n",
       "160  Software Engineering  South San Francisco, CA, United States   \n",
       "202  Software Engineering  South San Francisco, CA, United States   \n",
       "206  Software Engineering        Mountain View, CA, United States   \n",
       "210  Software Engineering        Mountain View, CA, United States   \n",
       "230   Technical Solutions        Mountain View, CA, United States   \n",
       "241    Program Management  South San Francisco, CA, United States   \n",
       "286  Software Engineering  South San Francisco, CA, United States   \n",
       "307          Partnerships                        München, Germany   \n",
       "\n",
       "    responsibilities                                            minqual  \\\n",
       "15               NaN                                                NaN   \n",
       "72               NaN                                                NaN   \n",
       "91               NaN                                                NaN   \n",
       "97               NaN                                                NaN   \n",
       "98               NaN                                                NaN   \n",
       "123              NaN                                                NaN   \n",
       "150              NaN                                                NaN   \n",
       "160              NaN                                                NaN   \n",
       "202              NaN                                                NaN   \n",
       "206              NaN                                                NaN   \n",
       "210              NaN                                                NaN   \n",
       "230              NaN                                                NaN   \n",
       "241              NaN                                                NaN   \n",
       "286              NaN                                                NaN   \n",
       "307              NaN  BA/BS degree or equivalent practical experienc...   \n",
       "\n",
       "                                              prefqual  \n",
       "15                                                 NaN  \n",
       "72                                                 NaN  \n",
       "91                                                 NaN  \n",
       "97                                                 NaN  \n",
       "98                                                 NaN  \n",
       "123                                                NaN  \n",
       "150                                                NaN  \n",
       "160                                                NaN  \n",
       "202                                                NaN  \n",
       "206                                                NaN  \n",
       "210                                                NaN  \n",
       "230                                                NaN  \n",
       "241                                                NaN  \n",
       "286                                                NaN  \n",
       "307  Relevant experience in sales management, busin...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['responsibilities'].isna() | df['minqual'].isna() | df['prefqual'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis of these last columns, it is probably better to leave aside the job posts with missing information. This is done with the method `dropna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With text data, missingness can also come as the empty string, white space, question marks (`?`), dashes (`-`), etc. One way to detect this is to check the length of the entries for these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['responsibilities'].str.len().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['minqual'].str.len().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prefqual'].str.len().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will focus the analysis to the column `prefqual`, which seems to have more content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the preferred qualifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last part of the example, the analysis focuses on the most frequent terms in the preferred qualifications posted by Google. There are different Python packages where you could find specific tools for that, but I skip them here.\n",
    "\n",
    "I put first everything in **lowercase**, with the method `str.lower`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experience in the business technology market as a program manager in saas, cloud computing, and/or emerging technologies.\\nsignificant cross-functional experience across engineering, sales, and marketing teams in cloud computing or related technical fields.\\nproven successful program outcomes from idea to launch in multiple contexts throughout your career.\\nability to manage the expectations, demands and priorities of multiple internal stakeholders based on overarching vision and success for global team health.\\nability to work under pressure and possess flexibility with changing needs and direction in a rapidly-growing organization.\\nstrong organization and communication skills.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefqual = df['prefqual'].str.lower()\n",
    "prefqual[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I extract the words with the method `findall`. As the pattern for the extraction, I use `\\w+'`, which stands for any uninterrupted sequence of characters that can be used to form a word. This includes numbers but leaves out numbers, **punctuation** and the **control character** '\\n', which means new line, and is used to separate paragraphs. `findall` returns a list called a **bag of words**. \n",
    "\n",
    "In this case, I will work with lists all the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "bags = [re.findall('\\w+', p) for p in prefqual]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For, instance, the first of these bags contains 94 terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experience',\n",
       " 'in',\n",
       " 'the',\n",
       " 'business',\n",
       " 'technology',\n",
       " 'market',\n",
       " 'as',\n",
       " 'a',\n",
       " 'program',\n",
       " 'manager']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bags[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I flatten `bags`, to have a single list of terms, instead of a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [t for b in bags for t in b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, I get 76,374 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76374"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the top frequent terms, with `value_counts`. Note that `terms` has to be converted to a Pandas series, in order to apply `value_coounts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and           5800\n",
       "to            2676\n",
       "in            2214\n",
       "with          2202\n",
       "experience    2168\n",
       "ability       1618\n",
       "of            1581\n",
       "a             1517\n",
       "or            1345\n",
       "skills        1224\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(terms).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it could be expected, we find on top terms that do not convey information, which is typical. There terms are called **stopwords**. I use here a list which comes in the file `stopwords.csv`, extracted from an Internet source. The file has one column, with no header, and one word in every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mcanela-iese/DataScience/main/Data/stopwords.csv'\n",
    "stopwords = pd.read_csv(url, header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source file comes without header. So, I use the argument `header=None` has been to stop `read_csv` taking the first stopword as the name of the column. With `squeeze=True`, I get a series instead of a data frame with one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I convert `stopwords` to a list with the function `tolist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I drop all the stopwords from `terms`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [t for t in terms if t not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52060"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-10 most frequent terms are, now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experience       2168\n",
       "ability          1618\n",
       "skills           1224\n",
       "management        645\n",
       "demonstrated      542\n",
       "excellent         505\n",
       "work              504\n",
       "business          501\n",
       "communication     501\n",
       "strong            453\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(terms).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term on top is experience. What is the proportion of job posts mentioning experience in the preferred qualifications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefqual.str.contains('experience').mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty high. Let me check a few terms more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefqual.str.contains('ability').mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.699"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefqual.str.contains('skills').mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.443"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefqual.str.contains('management').mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.476"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefqual.str.contains('communication').mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an alternative approach, you may start with a predefined list of words and check their inclusion in the preferred qualifications. This could be done without building the list of most frequent terms. For instance, suppose that you are interested in learning how often a languages like Python is explicitly mentioned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefqual.str.contains('python').mean().round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
